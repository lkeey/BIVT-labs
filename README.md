## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
name = input("–ò–º—è: ")
age = int(input("–í–æ–∑—Ä–∞—Å—Ç: "))
print(f"–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age + 1}.")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/01_greeting.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
a = float(input("A: ").replace(",", "."))
b = float(input("B: ").replace(",", "."))

print(f"sum={a + b}; avg={(a + b) / 2:.2f}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab01/02_sum_avg.png)

### –ó–∞–¥–∞–Ω–∏–µ 3
```python
price = float(input("–¶–µ–Ω–∞: "))
discount = float(input("–°–∫–∏–¥–∫–∞: "))
vat = float(input("–ù–î–°: "))

base = price * (1 - discount / 100)
vat_amount = base * (vat / 100)
total = base + vat_amount

print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} ‚ÇΩ")
print(f"–ù–î–°:               {vat_amount:.2f} ‚ÇΩ")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:    {total:.2f} ‚ÇΩ")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab01/03_discount_vat.png)

### –ó–∞–¥–∞–Ω–∏–µ 4
```python
m = int(input("–ú–∏–Ω—É—Ç—ã: "))
print(f"{m // 60:02d}:{m % 60:02d}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](./images/lab01/04_minutes_to_hhmm.png)

### –ó–∞–¥–∞–Ω–∏–µ 5
```python
fio = input("–§–ò–û: ")
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {''.join([i[0].upper() for i in fio.split()])}.")
print(f"–î–ª–∏–Ω–∞: {len(fio.strip())}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](./images/lab01/05_initials_and_len.png)

### –ó–∞–¥–∞–Ω–∏–µ 6
```python
n = int(input("–ü—Ä–∏—à–ª–æ –ª—é–¥–µ–π: "))
ochno = zaochno = 0
for i in range(n):
    info = input().split()
    if info[3] == "True":
        ochno += 1
    else:
        zaochno += 1

print(f"–û—á–Ω–æ: {ochno}; –ó–∞–æ—á–Ω–æ: {zaochno}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](./images/lab01/06_proga_people.png)

### –ó–∞–¥–∞–Ω–∏–µ 7
```python
hashed_str = input("–ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞: ")
correct_letter = [""]
first_index = -1

for i in range(len(hashed_str)):
    if hashed_str[i] in "ABCDEFGHIJKLMNOPQRSTUVWXYZ" and len(correct_letter[0]) == 0:
        correct_letter[0] = hashed_str[i]
        first_index = i
    elif (
        hashed_str[i] in "0123456789" and len(correct_letter) == 1 and first_index != -1
    ):
        step = i + 1 - first_index
        for j in range(i + 1, len(hashed_str), step):
            correct_letter.append(hashed_str[j])
        break
print("".join(correct_letter) + ".")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 7](./images/lab01/07_hashed_materials.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1.1
```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if len(nums) == 0:
        return ValueError

    mi = 9e6
    ma = -9e6

    for i in range(len(nums)):
        if nums[i] < mi:
            mi = nums[i]
        if nums[i] > ma:
            ma = nums[i]

    return tuple([mi, ma])
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab02/arrays_min_max.png)

### –ó–∞–¥–∞–Ω–∏–µ 1.2
```python
def unique_sorted(nums: list[float | int]) -> list[float | int]:
    return sorted(set(nums))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](./images/lab02/arrays_unique_sort.png)

### –ó–∞–¥–∞–Ω–∏–µ 1.3
```python
def flatten(mat: list[list | tuple]) -> list:
    array = list()
    for arr in mat:
        if not (isinstance(arr, tuple) or isinstance(arr, list)):
            return TypeError
        for member in arr:
            array.append(member)
    return array
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](./images/lab02/arrays_flatten.png)

### –ó–∞–¥–∞–Ω–∏–µ B.1
```python
def check_is_valid(mat: list[list[float | int]]) -> bool:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return False
    return True


def transpose(mat: list[list[float | int]]) -> list[list]:
    if len(mat) == 0:
        return []

    if not check_is_valid(mat=mat):
        return ValueError

    new_matrix = [[0 for j in range(len(mat))] for i in range(len(mat[0]))]

    for i in range(len(mat)):
        for j in range(len(mat[i])):
            new_matrix[j][i] = mat[i][j]

    return new_matrix
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](./images/lab02/matrix_transpose.png)

### –ó–∞–¥–∞–Ω–∏–µ B.2
```python
def check_is_valid(mat: list[list[float | int]]) -> bool:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return False
    return True

def row_sums(mat: list[list[float | int]]) -> list[float]:
    if not check_is_valid(mat=mat):
        return ValueError

    array = list()
    for arr in mat:
        array.append(sum(arr))
    return array
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 7](./images/lab02/matrix_row_sums.png)

### –ó–∞–¥–∞–Ω–∏–µ B.3
```python
def check_is_valid(mat: list[list[float | int]]) -> bool:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return False
    return True
    
def col_sums(mat: list[list[float | int]]) -> list[float]:
    if not check_is_valid(mat=mat):
        return ValueError

    array = list(0 for i in range(len(mat[0])))
    for i in range(len(mat)):
        for j in range(len(mat[i])):
            array[j] += mat[i][j]
    return array
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 8](./images/lab02/matrix_col_sums.png)

### –ó–∞–¥–∞–Ω–∏–µ C
```python
def format_record(rec: tuple[str, str, float]) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å—å –æ —Å—Ç—É–¥–µ–Ω—Ç–µ –≤ —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º—É—é —Å—Ç—Ä–æ–∫—É.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        rec (tuple[str, str, float]): –ö–æ—Ä—Ç–µ–∂ –∏–∑ —Ç—Ä—ë—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤:
            - rec[0]: –§–ò–û (—Ñ–∞–º–∏–ª–∏—è, –∏–º—è –∏, –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏, –æ—Ç—á–µ—Å—Ç–≤–æ) –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏,
                      –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞–ª–∏—á–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤.
            - rec[1]: –û–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã (—Å—Ç—Ä–æ–∫–∞).
            - rec[2]: –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª (GPA) ‚Äî —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π
                      –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ, –ø—Ä–∏–≤–æ–¥–∏–º–æ–µ –∫ float.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
             "–§–∞–º–∏–ª–∏—è –ò.–û., –≥—Ä. –ì–†–£–ü–ü–ê, GPA X.XX"

             –ü—Ä–∏–º–µ—Ä—ã:
             - ("–∏–≤–∞–Ω–æ–≤ –∏–≤–∞–Ω –∏–≤–∞–Ω–æ–≤–∏—á", "ABB-01", 4.55)
               ‚Üí "–ò–≤–∞–Ω–æ–≤ –ò.–ò., –≥—Ä. ABB-01, GPA 4.55"
             - ("—Å–∏–¥–æ—Ä–æ–≤–∞ –∞–Ω–Ω–∞", "CS-22", 3.9)
               ‚Üí "–°–∏–¥–æ—Ä–æ–≤–∞ A., –≥—Ä. CS-22, GPA 3.90"

    –ò—Å–∫–ª—é—á–µ–Ω–∏—è:
        ValueError:
            –ï—Å–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —É–∫–∞–∑–∞–Ω–æ –§–ò–û –∏–ª–∏ –≥—Ä—É–ø–ø–∞.

        TypeError:
            –ï—Å–ª–∏ —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥—Ä–æ–±–Ω–æ–µ —á–∏—Å–ª–æ.

    –ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
        - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –∏–º–µ–Ω–∞, —Å–æ—Å—Ç–æ—è—â–∏–µ –∏–∑ 1, 2 –∏–ª–∏ 3 —á–∞—Å—Ç–µ–π
          (—Ñ–∞–º–∏–ª–∏—è; —Ñ–∞–º–∏–ª–∏—è + –∏–º—è; —Ñ–∞–º–∏–ª–∏—è + –∏–º—è + –æ—Ç—á–µ—Å—Ç–≤–æ).
        - –õ–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ —Å—Ç—Ä–æ–∫–∞—Ö –§–ò–û –∏ –≥—Ä—É–ø–ø—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è.
    """

    name_data = rec[0].strip().split()

    if len(name_data) > 2:
        surname, name, patronymic = rec[0].strip().split()
        name_string_data = f"{surname[0].upper()}{surname[1:]} {name[0].upper()}.{patronymic[0].upper()}."
    elif len(name_data) == 2:
        surname, name = rec[0].strip().split()
        name_string_data = f"{surname[0].upper()}{surname[1:]} {name[0].upper()}."
    elif len(name_data) == 1:
        surname = rec[0].strip().split()
        name_string_data = f"{surname[0].upper()}{surname[1:]}"
    else:
        return ValueError

    group = rec[1].strip()
    if group == "":
        return ValueError

    try:
        gpa = float(rec[2])
    except Exception as _:
        return TypeError

    return f"{name_string_data}, –≥—Ä. {group}, GPA {gpa:.2f}"
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab02/tuples_format_record_success.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab02/tuples_format_record_error.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3

### –ó–∞–¥–∞–Ω–∏–µ A
```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞:
        - –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É (–µ—Å–ª–∏ casefold=True)
        - –∑–∞–º–µ–Ω—è–µ—Ç '—ë' ‚Üí '–µ' –∏ '–Å' ‚Üí '–ï' (–µ—Å–ª–∏ yo2e=True)
        - –∑–∞–º–µ–Ω—è–µ—Ç —Å–∏–º–≤–æ–ª—ã —Ç–∞–±—É–ª—è—Ü–∏–∏, –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫–∞—Ä–µ—Ç–∫–∏ –Ω–∞ –ø—Ä–æ–±–µ–ª
        - —Å–∂–∏–º–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–µ–ª–æ–≤ –¥–æ –æ–¥–Ω–æ–≥–æ
        - —É–¥–∞–ª—è–µ—Ç –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏

    –ü—Ä–∏–º–µ—Ä—ã:
        - "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t" ‚Üí "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä" (casefold + —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø—Ä–æ–±–µ–ª—ã)
        - "—ë–∂–∏–∫, –Å–ª–∫–∞" (yo2e=True) ‚Üí "–µ–∂–∏–∫, –µ–ª–∫–∞"
        - "Hello\r\nWorld" ‚Üí "hello world"
        - "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  " ‚Üí "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"
    """

    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace("—ë", "–µ").replace("–Å", "–ï")

    text = text.replace("\t", " ").replace("\r", " ").replace("\n", " ")

    while "  " in text:
        text = text.replace(" " * 2, " ")

    return text.strip()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.1](./images/lab03/A_normalize.png)

```python
def tokenize(text: str) -> list[str]:
    """
    –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞):
    - —Å–ª–æ–≤–æ–º —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤ \w (–±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ)
    - –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞–ª–∏—á–∏–µ –¥–µ—Ñ–∏—Å–∞ –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É')
    - —á–∏—Å–ª–∞ —Ç–∞–∫–∂–µ —Å—á–∏—Ç–∞—é—Ç—Å—è —Å–ª–æ–≤–∞–º–∏
    - —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –≤—Å–µ –Ω–µ–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã (–ø—Ä–æ–±–µ–ª—ã, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è, —ç–º–æ–¥–∑–∏ –∏ —Ç.–ø.)

    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:
        \w = [A-Za-z–ê-–Ø–∞-—è0-9_]
        (?:-\w+)* - –æ–∑–Ω–∞—á–∞–µ—Ç ¬´–Ω–æ–ª—å –∏–ª–∏ –±–æ–ª—å—à–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        –≤–∏–¥–∞ - + —Å–ª–æ–≤–æ¬ª (hello-world-2025)

    –ü—Ä–∏–º–µ—Ä—ã:
        "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä" ‚Üí ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]
        "hello,world!!!" ‚Üí ["hello", "world"]
        "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ" ‚Üí ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]
        "2025 –≥–æ–¥" ‚Üí ["2025", "–≥–æ–¥"]
        "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ" ‚Üí ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]
    """

    tokens = finditer(pattern=r"\w+(-\w+)*", string=text)

    return [i.group() for i in tokens]
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.2](./images/lab03/A_tokenize.png)

```python
def count_freq(tokens: list[str]) -> dict[str, int]:
    """
    –ü–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç—ã –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤.
    –ù–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—ë—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ (—Å—Ç—Ä–æ–∫).
    –ù–∞ –≤—ã—Ö–æ–¥–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä—å {—Ç–æ–∫–µ–Ω: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ}.

    –ü—Ä–∏–º–µ—Ä—ã:
        - ["a","b","a","c","b","a"] ‚Üí —á–∞—Å—Ç–æ—Ç—ã {"a":3,"b":2,"c":1};
        - –ü—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —á–∞—Å—Ç–æ—Ç: —Ç–æ–∫–µ–Ω—ã ["bb","aa","bb","aa","cc"] ‚Üí
        —á–∞—Å—Ç–æ—Ç—ã {"aa":2,"bb":2,"cc":1};

    """

    counts = {}

    for i in tokens:
        if i in counts:
            counts[i] += 1
        else:
            counts[i] = 1

    return counts

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    """
    –í—ã–±–æ—Ä–∫–∞ —Ç–æ–ø-N –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.
    - —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã
    - –ø—Ä–∏ —Ä–∞–≤–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ª–µ–∫—Å–∏–∫–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è (–ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É)
    - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Ç–æ–∫–µ–Ω, —á–∞—Å—Ç–æ—Ç–∞)

    –ü—Ä–∏–º–µ—Ä—ã:
        - top_n(..., n=2) ‚Üí [("a",3), ("b",2)]
        - top_n(..., n=2) ‚Üí [("aa",2), ("bb",2)]
        (–∞–ª—Ñ–∞–≤–∏—Ç–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ).
    """

    freq = sorted(freq.items(), key=lambda item: [-item[1], item[0]])
    top_n = []

    for i in range(min(n, len(freq))):
        top_n.append((freq[i][0], freq[i][1]))

    return top_n
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.3](./images/lab03/A_top_n.png)

### –ó–∞–¥–∞–Ω–∏–µ B
```python

def table(title: str, description: str, top: list[tuple[str, int]]) -> None:
    max_word_length = max([len(i[0]) for i in top]) + 1

    print(f"{title}{(max_word_length - 5) * ' '}| {description}")
    print("-" * (max_word_length + 2 + max_word_length))
    for i in top:
        word, count = i
        print(f"{word}{(max_word_length - len(word)) * ' '}| {count}")

"""
–§—É–Ω–∫—Ü–∏–∏:
    - –°—á–∏—Ç–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
    - –°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
    - –ù–∞—Ö–æ–¥–∏—Ç —Ç–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤

–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ src.lib.text:
    - normalize() ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç (–Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∑–∞–º–µ–Ω—è–µ—Ç '—ë' –Ω–∞ '–µ')
    - tokenize() ‚Äî —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞/—á–∏—Å–ª–∞
    - count_freq() ‚Äî —Å—á–∏—Ç–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤
    - top_n() ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-N –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤

–ó–∞–ø—É—Å–∫:
    –ò–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞:
        python3 -m src.lab03.text_stats < src/lab03/input.txt

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:
    IS_TABLE ‚Äî –µ—Å–ª–∏ True, –≤—ã–≤–æ–¥–∏—Ç—Å—è –∫—Ä–∞—Å–∏–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞; –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–∞—è –ø–µ—á–∞—Ç—å —Ç–æ–∫–µ–Ω:—á–∞—Å—Ç–æ—Ç–∞
"""

IS_TABLE = True

text = sys.stdin.read()

text = normalize(text=text)

tokens = tokenize(text=text)

top = top_n(count_freq(tokens=tokens), n=5)

print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokens))}")
print("–¢–æ–ø-5:")

if IS_TABLE:
    table(title="c–ª–æ–≤–æ", description="—á–∞—Å—Ç–æ—Ç–∞", top=top)
else:
    for i in top:
        print(f"{i[0]}:{i[1]}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.3](./images/lab03/B.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4

### –ó–∞–¥–∞–Ω–∏–µ A
```python
from pathlib import Path
import csv
from typing import Iterable, Sequence
from collections import Counter
from src.lib.text import normalize, tokenize

"""
–§—É–Ω–∫—Ü–∏–∏:
    - read_text: —á—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Ü–µ–ª–∏–∫–æ–º
    - write_csv: –∑–∞–ø–∏—Å—å —Å—Ç—Ä–æ–∫ –≤ CSV-—Ñ–∞–π–ª
    - ensure_parent_dir: —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - frequencies_from_text: —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç normalize/tokenize –∏–∑ –õ–†3)
    - sorted_word_counts: —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å–ª–æ–≤ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã –∏ –∞–ª—Ñ–∞–≤–∏—Ç—É

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    from src.lab04.io_txt_csv import read_text, write_csv

    txt = read_text("data/input.txt")   # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
    write_csv([("word", "count"), ("test", 3)], "data/check.csv")  # —Å–æ–∑–¥–∞—Å—Ç CSV

–ö—Ä–∞–µ–≤—ã–µ —Å–ª—É—á–∞–∏:
    - –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª -> –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞.
    - –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª -> —á–∏—Ç–∞–µ—Ç—Å—è —Ü–µ–ª–∏–∫–æ–º (–ø–æ –Ω–∞—à–µ–º—É –¢–ó).
      –í README —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ—Å—Ç—Ä–æ—á–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    - write_csv([], "file.csv", header=None) -> —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª (0 —Å—Ç—Ä–æ–∫).
    - write_csv([], "file.csv", header=("a","b")) -> —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫.
"""


def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """
    –û—Ç–∫—Ä—ã—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏ –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ pathlib.Path).
        encoding: –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "utf-8").
                  –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –¥—Ä—É–≥–∞—è, –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä: encoding="cp1251".

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        str: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.

    –ü–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–∞–º–∏:
        FileNotFoundError: –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.
        UnicodeDecodeError: –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É.
    """

    p = Path(path)
    return p.read_text(encoding=encoding)


def ensure_parent_dir(path: str | Path) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏, –µ—Å–ª–∏ –∏—Ö –µ—â—ë –Ω–µ—Ç.

    Args:
        path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ pathlib.Path).
    """
    p = Path(path)
    if p.parent and not p.parent.exists():
        p.parent.mkdir(parents=True, exist_ok=True)


def write_csv(
    rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å CSV-—Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ','.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        rows: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–æ–∫ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî tuple –∏–ª–∏ list).
        path: –ø—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ pathlib.Path).
        header: –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (tuple[str,...]), –±—É–¥–µ—Ç –∑–∞–ø–∏—Å–∞–Ω –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π.

    –ü–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π:
        ValueError: –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∏ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É.
    """

    p = Path(path)
    ensure_parent_dir(p)

    rows = list(rows)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)


def frequencies_from_text(text: str) -> dict[str, int]:
    """
    –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è normalize/tokenize –∏–∑ –õ–†3.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        dict[str, int]: —Å–ª–æ–≤–∞—Ä—å —Å–ª–æ–≤–æ -> —á–∞—Å—Ç–æ—Ç–∞.
    """

    tokens = tokenize(normalize(text))
    return Counter(tokens)  # dict-like


def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    """
    –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—ã (—Å–ª–æ–≤–æ, —á–∞—Å—Ç–æ—Ç–∞):
      - —Å–Ω–∞—á–∞–ª–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã,
      - –∑–∞—Ç–µ–º –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        freq: —Å–ª–æ–≤–∞—Ä—å —Å–ª–æ–≤–æ -> —á–∞—Å—Ç–æ—Ç–∞.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        list[tuple[str, int]]: –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫.
    """

    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.1](./images/lab04/A_empty_header.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.2](./images/lab04/A_empty_input.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.3](./images/lab04/A_test.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.4](./images/lab04/A_top.png)

### –ó–∞–¥–∞–Ω–∏–µ B

```python
from src.lab04.io_txt_csv import (
    read_text,
    write_csv,
    frequencies_from_text,
    sorted_word_counts,
)
import argparse
from src.lib.table import print_summary


def main():
    """
    –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ –≤ CSV.

    –°–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç:
        1. –ß–∏—Ç–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª (--in, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é data/input.txt).
        2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç (—Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ src/lib/text.py).
        3. –°—á–∏—Ç–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤.
        4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ CSV (--out, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é data/report.csv)
           —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: word,count (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –∑–∞—Ç–µ–º –ø–æ —Å–ª–æ–≤—É).
        5. –ü–µ—á–∞—Ç–∞–µ—Ç —Ä–µ–∑—é–º–µ –≤ –∫–æ–Ω—Å–æ–ª—å:
            - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å–µ—Ö —Å–ª–æ–≤
            - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
            - —Ç–æ–ø-5 —Å–ª–æ–≤ (–≤ —Ç–∞–±–ª–∏—á–Ω–æ–π —Ñ–æ—Ä–º–µ –∏–ª–∏ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞).

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏:
        --in <–ø—É—Ç—å>       –ø—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é data/input.txt)
        --out <–ø—É—Ç—å>      –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é data/report.csv)
        --encoding <–∫–æ–¥>  –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é utf-8).
                          –ù–∞–ø—Ä–∏–º–µ—Ä: --encoding cp1251

    –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—É—Å–∫–∞:
        python3 -m src.lab04.text_report
        python3 -m src.lab04.text_report --in data/lab04/b.txt --out data/report.csv
        python3 -m src.lab04.text_report --in data/lab04/a.txt --encoding cp1251u

    –ü–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–∞–º–∏:
        - –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Üí FileNotFoundError.
        - –ï—Å–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç ‚Üí UnicodeDecodeError.
        - –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª ‚Üí report.csv –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    """

    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –æ—Ç—á—ë—Ç –≤ CSV")
    parser.add_argument("--in", dest="input", default="data/lab04/input.txt")
    parser.add_argument("--out", dest="output", default="data/report.csv")
    parser.add_argument("--encoding", dest="encoding", default="utf-8")
    args = parser.parse_args()

    text = read_text(
        path=args.input,
        encoding=args.encoding,
    )
    freq = frequencies_from_text(text)
    data = sorted_word_counts(freq)

    write_csv(
        header=("word", "count"),
        rows=data,
        path=args.output,
    )

    print_summary(text=text, is_table=True)


main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.5](./images/lab04/B_empty_parser.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.6](./images/lab04/B_encoding.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.7](./images/lab04/B_in&out.png)
